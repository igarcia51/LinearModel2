---
title: "LinearModel2"
author: "Irene"
date: "12/2/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv(file="https://onlinestatbook.com/case_studies_rvls/physical_strength/data.txt",sep="",header=TRUE)
require(tidyverse)
require(tigerstats)
```

## Introduction

Form three regression models; Model1 is SIMS~ARM, Model2 is SIMS~GRIP, and Model3 is SIMS~ARM+GRIP. For each model find a 95% prediction interval of SIMS given a value of 94  for GRIP and 88 for ARM. Compare Model1 with Model3 using anova. Write it up in a markdown document, push the project up to your github account and submit it back to canvas as link. 

## SIMS~ARM regression

```{r}
plot(SIMS~ARM,data=data)
```

The greater the pounds of arm force(ARM), the greater the simulation(SIMS)


```{r}
cor(SIMS~ARM,data=data)
```
This number is the correlation between SIMS and ARM force. Correlation is a measure of the linear association between the two variables.


```{r}
model.1 <- lm(SIMS~ARM,data=data)
summary.lm(model.1)
```

The equation is -4.095160 +  0.054563 * ARM

```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=ARM))
```

```{r}
basicNN + geom_point() + geom_smooth(method=lm)
```

The scatter plot shows the blue line which is best linear fitto predict what what an average SIMS response would be for any ARM strength.

The shaded pasr is uncertainty of blue line itself.

Shows all of the data points of each individual score and corresponding Arm strength. 

```{r}
newData=data.frame(GRIP=94,ARM=88)
predict.lm(model.1,newData, interval="prediction")
```

Fit is the predicted ARM score when you have an Arm strength of 88.

The lower and upper are the 95% confidence intervals for predicted SIMS score when the ARM is 88.

## SIMS~GRIP regression

```{r}
plot(SIMS~GRIP,data=data)
```
The greater the pounds of GRIP force (GRIP), the greater the simulation (SIMS)

```{r}
cor(SIMS~GRIP,data=data)
```
 
 This number is the correlation between SIMS and GRIP force. Correlation is a measure of linear association between the two variables.
 
```{r}
model.1 <- lm(SIMS~GRIP,data=data)
summary.lm(model.1)
```

The equation is SIMS = -4.809675 + 0.045463 * GRIP

```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=GRIP))
```

```{r}
basicNN + geom_point() + geom_smooth(method=lm)
``` 

This scatter plot shows the blue line which is best linear fit to predict what an average SIMS response would be for any ARM strength.

The shaded part is the uncertainty of the blue line itself.

Show all of the data points of each individual score and corresponding GRIP strength.

```{r}
newData=data.frame(GRIP=94,ARM=88)
predict.lm(model.1,newData, interval="prediction")
```

Fit is the predicted SIMS score when you have a GRIP strength of 94.

The lower and upper are the 95% confidence intervals for predicted SIMS score when the Grip score is 94.

comparing the two models , model1 and model2 

model1(SIMS~ARM) has a slightly lower residual standard error score of 1.226 while model2(SIMS~GRIP) scored at 1.295

model1 (SIMS~ARM) has a higher adjusted r squared score of 0.467 while model2(SIMS~GRIP) scored lower 0.4053

model2 apperars to be slighlty better model because it has a  lower residual standard error score than model1 and also has a higher adjusted r squared score than model2.

## SIMS~ARM+GRIP regression

```{r}
advNN <- ggplot(data,aes(y=SIMS,x=ARM,z=GRIP))
```

```{r}
model.2 <- lm(SIMS~ARM + GRIP,data=data)
summary.lm(model.1)
``` 

model3 appears to be the better model because adjusted r squared score was higher than model2 and also scored lower in the residual standard error than model1 or model2.

```{r}
cor(SIMS~ARM+GRIP,data=data)
```

## prediction

```{r}
newData=data.frame(GRIP=94,ARM=88)
predict.lm(model.2,newData, interval="prediction")
```

fit is the predicted SIMS score when you have a GRIP strength 94 and ARM strength of 88.

The lower and upper are 95% confidence intervals for predicted SIMS score when the GRIP score is 94 and ARM strength of 88. 

## Inferential tests 

This is the inferential tests to compare models.

The test is anova 

$H_0$: Theres no difference in how well each model fit the data between models (model2,model3)

$H_A$:  Theres is a difference in how well each model fit the data between models (model2,model3)

```{r}
anova(model.1,model.2)
```

The P- value is 0.00004994 which is very low .

We reject the null hypothesis because the p value is too low. There is a difference between model2, and model3. We have evidence that model3 is btter than model2.



